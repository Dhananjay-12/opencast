# Change enabled to true to enable this service.
enabled=false

# Microsoft Azure Service details
subscription.key=
region=

# Language code of the supplied audio. See the Google Speech-to-Text service documentation
# for available languages. If empty, the default will be used ("en-US").
# List of supported languages: https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=stt-tts
#language=en-US

# Setting this option will prompt Azure to detect the spoken language by itself. Language is detected once at the
# start of the media file. Auto detection will take precedence over a defined language.
# Default: false
#auto.detect.language=false

# A list of language codes. The Azure language auto detection will pick it's detected language from one of these.
# The language auto detection cannot detect any languages not specified in this list.
# The list needs to have at least one element and can have at most four elements.
# List of supported languages: https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=language-identification
# Example: en-US,de-DE,fr-FR,it-IT
# Default: None
#auto.detect.languages=

# Filter out profanities from result. Valid values: raw, remove, mask
# Raw: Includes the profanity in the result.
# Remove: Removes all profanity from the result.
# Mask: Replaces profanity with asterisks.
#profanity.option=Raw

# Default is VTT. Set this to true if you want SRT instead.
#use.subrip.format=false

# A phrase list is a list of words or phrases provided ahead of time to help improve their recognition. Adding a phrase
# to a phrase list increases its importance, thus making it more likely to be recognized.
# Maximum of 500 phrases, provided as a commma seperated list
# Examples: Names, Geographical locations, Homonyms, Words or acronyms unique to your industry or organization
# Example: Opencast,Github,ETH,Osnabr√ºck
#phrases.list=

# Audio stream container format
# Format of the source file. If you are not explicitely converting your files to the mentioned format prior to sending
# them to the transcription service, leave this as ANY
# Possible values: ALAW, AMRNB, AMRWB, ANY, FLAC, MP3, MULAW, OGG_OPUS
# Default: ANY
#encoding.extension=ANY

# Set this to true if you want to limit the maximum size of a line in the subtitle file.
# Azure does not do this automatically, and sometimes produces very long lines.
# Default: false
#split.text=false

# The maximum amount of characters a single line in the subtitle file should contain.
# Can go over the set number to avoid cutting words in half.
# Only takes effect if "split.text" is set to true.
# Default: 100
#split.text.line.size=100

# Workflow to be executed when results are ready to be attached to media package.
#workflow=microsoft-azure-attach-transcripts

# Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package
# after the transcription job is completed.
# (in seconds) Default is 1 minute.
#workflow.dispatch.interval=60

# How long it should wait to check jobs after their start date + track duration has passed.
# The default is 5 minutes.
# (in seconds)
#completion.check.buffer=300

# How long to wait after a transcription is supposed to finish before marking the job as
# cancelled in the database. Default is 5 hours.
# (in seconds)
#max.processing.time=18000

# How long to keep result files in the working file repository in days.
# The default is 7 days.
#cleanup.results.days=7

# Email to send notifications of errors. If not entered, the value from
# org.opencastproject.admin.email in custom.properties will be used.
#notification.email=
